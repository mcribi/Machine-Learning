{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["sbmdqr0DZgnx","yT5j6lZOAqix"],"authorship_tag":"ABX9TyOC1SYBJLZshfybNP21vGb9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Asignatura**: Aprendizaje Automático\n","\n","**Práctica 3**: Introducción a Deep Learning\n","\n","**Valoración máxima**: 10 puntos\n","\n","**Fecha límite de entrega**: 23 de Mayo de 2025 a las 23:59\n","\n","**Procedimiento de entrega**: a través de PRADO\n","\n","### Nombre completo: <mark>POR FAVOR, ESCRIBA AQUÍ SU NOMBRE</mark>\n","\n","\n"],"metadata":{"id":"3TeHZc1FZKAi"}},{"cell_type":"markdown","source":["\n","**Normas de desarrollo y entrega de trabajos**\n","\n","- Única y exclusivamente se debe entregar este Notebook de Colab (fichero `.ipynb`). **No es necesario entregar ninguna memoria externa** (por ejemplo, en `.pdf`).\n","\n","- El código debe estar bien comentado (explicando lo que realizan los distintos apartados y/o bloques), y todas las decisiones tomadas y el trabajo desarrollado (incluyendo los conceptos fundamentales subyacentes) deben documentarse ampliamente en celdas de texto. Es obligatorio documentar las valoraciones y decisiones adoptadas en el desarrollo de cada uno de los apartados. Debe incluirse también tanto una descripción de las principales funciones (Python/scikit-learn) empleadas (para mostrar que el alumno comprende, a nivel técnico, lo que está haciendo), como una valoración razonada sobre la calidad de los resultados obtenidos. **Sin esta documentación, se considera que el trabajo NO ha sido presentado**.\n","\n","- La entrega en PRADO está configurada para permitir sucesivas entregas de la práctica. Desde este punto de vista, se recomienda subir versiones de la práctica a medida que se van realizando los distintos ejercicios propuestos, y no dejarlo todo para el final.  \n","\n","- Se debe respetar la estructura y secciones del Notebook. Esto servirá para agilizar las correcciones, así como para identificar con facilidad qué ejercicio/apartado se está respondiendo.\n","\n","- El código **NO debe escribir nada a disco**.\n","\n","- El **path de lectura desde Google Drive debe ser siempre el mismo**, que es el que se indica en este Notebook.\n","\n","- Una entrega es apta para ser corregida si se puede ejecutar de principio a fin sin errores. Es decir, un ejercicio con errores de ejecución tendrá una calificación de 0.\n","\n","- No es válido usar opciones en las entradas (es decir, utilizar el comando `input()`, por ejemplo, para que el usuario escoja el valor de las variables para ejecutar el programa). Para ello, se deben fijar al comienzo los valores\n","por defecto que se consideren óptimos o que se soliciten en el enunciado.\n","\n","- Se entrega solamente este Notebook, y no los datos empleados.\n"],"metadata":{"id":"wy3wC6uhZXsx"}},{"cell_type":"markdown","source":["# **Ejercicio 1: Clasificación (5 puntos)**"],"metadata":{"id":"sbmdqr0DZgnx"}},{"cell_type":"markdown","source":["En este ejercicio los alumnos se enfrentarán a un problema de clasificación, el cual tendrán que abordar de comienzo a fin (desde el análisis exploratorio hasta el entrenamiento y validación de los modelos de aprendizaje automático seleccionados). En particular, se enfrentarán a un problema real de uso de técnicas de aprendizaje automático para tratar de clasificar imágenes que contienen prendas de ropa, prediciendo la categoría de la imagen de entrada que contiene la prenda. El conjunto de datos original se obteniene a partir de la investigación realizada en el siguiente artículo:\n","\n","- Han Xiao, Kashif Rasul, Roland Vollgraf, Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms, Technical Report, ArXiv, 2017 (URL: <a href=\"https://arxiv.org/abs/1708.07747\">https://arxiv.org/abs/1708.07747</a>)."],"metadata":{"id":"Cto6L5TrZl6z"}},{"cell_type":"markdown","source":["## El conjunto de datos"],"metadata":{"id":"hxFvGS7SaXNo"}},{"cell_type":"markdown","source":["**Fashion-MNIST** es un conjunto de datos que contiene imágenes de artículos de venta online desde la web de **Zalando**. Se distribuye en dos conjuntos de entrenamiento (60.000 imágenes) y test (10.000 imágenes) de prendas de ropa en escala de grises, donde cada imagen tiene un tamaño de 28 filas y 28 columnas. Cada una de las prendas se corresponde con una etiqueta entre 10 classes posibles:\n","\n","- 0 T-shirt/top\n","- 1 Trouser\n","- 2 Pullover\n","- 3 Dress\n","- 4 Coat\n","- 5 Sandal\n","- 6 Shirt\n","- 7 Sneaker\n","- 8 Bag\n","- 9 Ankle boot\n","\n","Una muestra de ejemplo del contenido del conjunto de datos se ilustra en la siguiente figura:\n","\n","<center>\n","<img src=\"https://github.com/zalandoresearch/fashion-mnist/raw/master/doc/img/fashion-mnist-sprite.png\" />\n","</center>\n","\n","\n","El **objetivo de la práctica** es desarrollar un modelo de aprendizaje automático con **Keras** capaz de identificar, si es posible, la categoría a la que pertenece cada prenda de ropa, tratando de alcanzar el máximo rendimiento en la resolución del problema.\n","\n","El dataset se encuentra disponible en **Keras**, y puede leerse como se muestra en la siguiente celda de código:"],"metadata":{"id":"rl5xTIlnaY4-"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","Train, Test= tf.keras.datasets.fashion_mnist.load_data()\n","print('Conjunto de training: ', type(Train), len(Train))\n","print('Conjunto de test: ', type(Test), len(Test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SVLZ7y3_ZbJS","executionInfo":{"status":"ok","timestamp":1737724427053,"user_tz":-60,"elapsed":10351,"user":{"displayName":"manuel PEGALAJAR CUELLAR","userId":"14960860166964833834"}},"outputId":"441be4a9-60a6-4dfa-c068-ab6db9ed2535"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","Conjunto de training:  <class 'tuple'> 2\n"]}]},{"cell_type":"markdown","source":["## Tarea"],"metadata":{"id":"mgkADWAncwFx"}},{"cell_type":"markdown","source":["El alumnado debe realizar, al menos, las siguientes tareas (que deben ser descritas y abordadas, explícitamente, en la documentación entregada; de hecho, se debe incluir un subapartado en el Notebook para cada una de ellas):\n","\n","1. Análisis descriptivo del problema y análisis exploratorio de los datos a nuestra disposición.\n","2. Preprocesado de datos (selección/extracción de características, reducción de dimensionalidad, procesado de datos extremos/atípicos, imputación de datos faltantes, escalado de variables, codificación/transformación de datos, desbalanceo de datos).\n","3. Definición del protocolo de validación experimental (entrenamiento, validación y test), junto con las métricas de evaluación del rendimiento que corresponda.\n","4. Selección de dos tipos de modelos distintos de **Deep Learning**: Al primero lo llamaremos **C1** y al segundo **C2**.\n","5. Selección y estimación de valores para hiperparámetros.\n","6. Entrenamiento y estimación del error fuera de la muestra. Discusión de resultados y extracción de conclusiones.\n","\n","\n","Con respecto a los modelos a utilizar, partiremos de la propuesta realizada en el siguiente artículo:\n","\n","- E. Xhaferra, E. Cina and L. Toti, \"Classification of Standard FASHION MNIST Dataset Using Deep Learning Based CNN Algorithms,\" 2022 International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), Ankara, Turkey, 2022, pp. 494-498, doi: 10.1109/ISMSIT56059.2022.9932737 (URL: <a href=\"https://ieeexplore.ieee.org/document/9932737\">https://ieeexplore.ieee.org/document/9932737</a>.\n","\n","\n","\n","\n","La arquitectura de la red para el modelo **C1** es la siguiente:\n","\n","<table>\n","<th>\n","  <td><b>Layer Type</b></td>\n","  <td><b>kernel type (conv.)</b></td>\n","  <td><b>Input | Output dim.</b></td>\n","  <td><b>Input | Output channels (conv.)</b></td>\n","</th>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 26x26 </td>\n","  <td> 1 | 6 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> MaxPooling </td>\n","  <td> 2x2 </td>\n","  <td> 26x26 | 13x13 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 13x13 | 11x11 </td>\n","  <td> 6 | 10 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Batch Norm. </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> MaxPooling </td>\n","  <td> 2x2 </td>\n","  <td> 11x11 | 5x5 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 250 | 128 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 128 | 10 </td>\n","  <td> - </td>\n","</tr>\n","</table>\n","\n","\n","\n","Por otra parte, la arquitectura de la red para el modelo **C2** es la siguiente:\n","\n","<table>\n","<th>\n","  <td><b>Layer Type</b></td>\n","  <td><b>kernel type (conv.)</b></td>\n","  <td><b>Input | Output dim.</b></td>\n","  <td><b>Input | Output channels (conv.)</b></td>\n","</th>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 1 | 112 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Batch Norm. </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 112 | 64 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Batch Norm. </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 64 | 128 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Batch Norm. </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> MaxPooling </td>\n","  <td> 2x2 </td>\n","  <td> 28x28 | 14x14 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 25088 | 208 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Dropout(0.1) </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 208 | 160 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Dropout(0.1) </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 160 | 128 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Dropout(0.1) </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> FC </td>\n","  <td> - </td>\n","  <td> 128 | 10 </td>\n","  <td> - </td>\n","</tr>\n","</table>\n","\n","\n","**Entrene cada modelo un total de 20 épocas. Pruebe con dos tipos de tamaño de batch (64 y 1000) en cada modelo.**.\n","\n","<font color=\"red\"><b>NO OLVIDAR ACTIVAR LA GPU EN LA CONFIGURACIÓN DEL CUADERNO (Menú Editar -> Configuración del cuaderno)</b></font>"],"metadata":{"id":"lHfRbuOGcxJ1"}},{"cell_type":"markdown","source":["## Solución: Modelo C1\n"],"metadata":{"id":"5eiHFvHQkaCE"}},{"cell_type":"markdown","source":["## Solución: Modelo C2"],"metadata":{"id":"dSAtXUD9kc7N"}},{"cell_type":"markdown","source":["## Comparativa de los modelos C1 y C2"],"metadata":{"id":"yLmmgxZIkeSc"}},{"cell_type":"code","source":[],"metadata":{"id":"6Dl5mbvYcjC-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Ejercicio 2: IA generativa con Autoencoders (5 puntos)**"],"metadata":{"id":"yT5j6lZOAqix"}},{"cell_type":"markdown","source":["En este ejercicio los alumnos se enfrentarán a un problema utilizando autoencoders, el cual tendrán que abordar de comienzo a fin (desde el análisis exploratorio hasta el entrenamiento y validación de los modelos de aprendizaje automático seleccionados). En particular, se enfrentarán a un problema  de **Inteligencia Artificial Generativa** haciendo uso de técnicas de Deep Learning para tratar de generar imágenes que contienen dígitos manuscritos."],"metadata":{"id":"foprMKRmTbK6"}},{"cell_type":"markdown","source":["## Contexto del problema"],"metadata":{"id":"sinWGGEUTbZq"}},{"cell_type":"markdown","source":["La **IA generativa** es un tipo de Inteligencia Artificial que se centra en crear contenido nuevo y original. Esto puede incluir texto, imágenes, música, vídeo, etc. A diferencia de otros tipos de IA que se enfocan en analizar o clasificar datos, la IA generativa utiliza modelos complejos para aprender patrones y características de los datos existentes y luego generar algo nuevo basado en ese aprendizaje.\n","\n","Un ejemplo popular de IA generativa son los modelos de lenguaje, como **ChatGPT**. Estos modelos pueden escribir historias, responder preguntas o incluso mantener una conversación, todo basado en la información con la que fueron entrenados.\n","\n","La IA generativa también se utiliza en el arte, donde puede crear obras visuales sorprendentes, o en la música, donde puede componer melodías. Sin embargo, es importante tener en cuenta que, aunque puede producir resultados impresionantes, la calidad y la relevancia del contenido generado pueden variar.\n","\n","<center>\n","<img src=\"https://bernardmarr.com/wp-content/uploads/2024/02/13-Ways-Writers-Should-Embrace-Generative-AI.webp\" />\n","</center>\n","\n","En esta práctica **vamos a hacer uso de autoencoders** para aprender las características de dígitos manuscritos, de modo que podamos utilizar el modelo entrenado **para generar nuevos dígitos previamente inexistentes**.\n","\n","En particular, el modelo que deseamos construir constará de dos partes:\n","\n","- Un **encoder**, capaz de obtener una imagen de entrada conteniendo un dígito manuscrito y dar como salida su *embedding*.\n","- Un **decoder**, cada de generar una imagen a partir de un *embedding*.\n"],"metadata":{"id":"TMFSu6WvTdfK"}},{"cell_type":"markdown","source":["## El conjunto de datos"],"metadata":{"id":"qY7J9sRnTdjT"}},{"cell_type":"markdown","source":["Utilizaremos el conjunto de datos de Digits MNIST incluido en TensorFlow, el cual se puede cargar utilizando el código de la siguiente celda:"],"metadata":{"id":"CdjchX3DTfHS"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","train, test= tf.keras.datasets.mnist.load_data()\n","XTrain, YTrain= train\n","XTest, YTest= test"],"metadata":{"id":"PMHDaJ0yVSHD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tarea"],"metadata":{"id":"Gp-Nms-IVoHm"}},{"cell_type":"markdown","source":["El alumnado debe realizar, al menos, las siguientes tareas (que deben ser descritas y abordadas, explícitamente, en la documentación entregada; de hecho, se debe incluir un subapartado en el Notebook para cada una de ellas):\n","\n","1. Análisis descriptivo del problema y análisis exploratorio de los datos a nuestra disposición.\n","2. Preprocesado de datos (selección/extracción de características, reducción de dimensionalidad, procesado de datos extremos/atípicos, imputación de datos faltantes, escalado de variables, codificación/transformación de datos, desbalanceo de datos).\n","3. Definición del protocolo de validación experimental (entrenamiento, validación y test), junto con las métricas de evaluación del rendimiento que corresponda.\n","4. Construcción de **tres modelos**:\n","    1. **Encoder**, para codificar datos de entrada en *embeddings*.\n","    2. **Decoder**, para decodificar *embeddings*.\n","    3. **Autoencoder**, formado como la concatenación secuencial del **Encoder** y el **Decoder**\n","5. Selección y estimación de valores para hiperparámetros.\n","6. Validación del modelo. Discusión de resultados y extracción de conclusiones.\n","\n","\n","Con respecto a los modelos a utilizar, usaremos la siguiente estructura para el **Encoder**:\n","\n","\n","<table>\n","<th>\n","  <td><b>Layer Type</b></td>\n","  <td><b>kernel type (conv.)</b></td>\n","  <td><b>Input | Output dim.</b></td>\n","  <td><b>Input | Output channels (conv.)</b></td>\n","</th>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 1 | 64 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 64 | 32 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> MaxPooling </td>\n","  <td> 2x2 </td>\n","  <td> 28x28 | 14x14 </td>\n","  <td> - </td>\n","</tr>\n","\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 14x14 | 14x14 </td>\n","  <td> 32 | 16 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> MaxPooling </td>\n","  <td> 2x2 </td>\n","  <td> 14x14 | 7x7 </td>\n","  <td> - </td>\n","</tr>\n","</table>\n","\n","\n","El **Decoder** deberá *deshacer* la codificación realizada por el **Encoder**, por lo que estableceremos una arquitectura de capas simétrica al primer módulo:\n","\n","<table>\n","<th>\n","  <td><b>Layer Type</b></td>\n","  <td><b>kernel type (conv.)</b></td>\n","  <td><b>Input | Output dim.</b></td>\n","  <td><b>Input | Output channels (conv.)</b></td>\n","</th>\n","\n","<tr>\n","  <td></td>\n","  <td> UpSampling2D </td>\n","  <td> 2x2 </td>\n","  <td> 7x7 | 14x14 </td>\n","  <td> 16 | 16 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 14x14 | 14x14 </td>\n","  <td> 16 | 32 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","\n","<tr>\n","  <td></td>\n","  <td> UpSampling2D </td>\n","  <td> 2x2 </td>\n","  <td> 14x14 | 28x28 </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 32 | 64 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> Conv </td>\n","  <td> 3x3 </td>\n","  <td> 28x28 | 28x28 </td>\n","  <td> 64 | 1 </td>\n","</tr>\n","<tr>\n","  <td></td>\n","  <td> ReLU </td>\n","  <td> - </td>\n","  <td> - </td>\n","  <td> - </td>\n","</tr>\n","</table>\n","\n","\n","**Entrene el autoencoder un total de 50 épocas con tamaño de batch 1000. Use una función de pérdida habitual para resolución de problemas de regresión**.\n","\n","<font color=\"red\"><b>NO OLVIDAR ACTIVAR LA GPU EN LA CONFIGURACIÓN DEL CUADERNO (Menú Editar -> Configuración del cuaderno)</b></font>\n","\n","\n","Cuando el modelo **autoencoder** ya esté entrenado, además de su validación con el conjunto de test, realice las siguientes pruebas:\n","\n","- **Usando sólo el encoder**:\n","   1. Seleccione todas las imágenes de un mismo dígito (por ejemplo, el dígito 0).\n","   2. Envíe esas imágenes como entrada al encoder, y obtenga los resultados de los embeddings.\n","   3. Calcule un **embedding promedio** calculando la media de cada componente de todos los embeddings.\n","\n","- **Usando sólo el decoder**:\n","   4. Proporcione este nuevo **embedding promedio** como entrada al **Decoder**. ¿Qué se obtiene? ¿Es lógico el resultado?\n","\n","\n","- Realice los pasos anteriores del **Encoder** con todos los dígitos pero, en este caso, guarde el valor promedio y de desviación estándar (a este último lo denominaremos **embedding de desviación**.\n","- Genere, para cada dígito, varios **nuevos embeddings** simulando un muestreo desde una distribución normal de media el embedding promedio y desviación típica el embedding de desviación.\n","- Utilice los **embeddings nuevos** como entrada al módulo **Decoder**. ¿Qué se obtiene?\n","- Analice y discuta los resultados obtenidos.\n","\n"],"metadata":{"id":"Ez67y8wPVpHD"}},{"cell_type":"code","source":[],"metadata":{"id":"1BuS0CHEW2el"},"execution_count":null,"outputs":[]}]}